{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case - Text Analysis\n",
    "\n",
    "\n",
    "\n",
    "## Word Frequency\n",
    "\n",
    "\n",
    "As usual, you should at least attempt the exercises before you read the following solutions.\n",
    "\n",
    "### ***Exercise 01***\n",
    "\n",
    "Modify function <code>process_file</code> to read a file, break each line into words, strip whitespace and punctuation from the words, and convert them to lowercase.\n",
    "\n",
    "Hint: The <code>string</code> module provides a string named <code>whitespace</code>, which contains space, tab, newline, etc., and <code>punctuation</code> which contains the punctuation characters. Let’s see if we can make Python swear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you might consider using the string methods <code>strip</code>, <code>replace</code> and <code>translate</code>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exercise 02***  \n",
    "\n",
    "Go to Project Gutenberg (http://gutenberg.org) and download your favorite out-of-copyright book in plain text format.\n",
    "\n",
    "Modify your program from the previous exercise to read the book you downloaded, skip over the header information at the beginning of the file, and process the rest of the words as before. (<code>skip_gutenberg_header</code>)\n",
    "\n",
    "Then modify <code>total_words</code> to count the total number of words in the book, and the number of times each word is used.\n",
    "\n",
    "Then modify <code>different_words</code> to print the number of different words used in the book. Compare different books by different authors, written in different eras. Which author uses the most extensive vocabulary? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exercise 03*** \n",
    "\n",
    "Modify <code>most_common</code> and <code>print_most_common</code> to print the 20 most frequently used words in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional parameters\n",
    "\n",
    "We have seen built-in functions and methods that take optional arguments. It is possible to write programmer-defined functions with optional parameters, too. For example, here is a function that prints the most common words in a histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_common(hist, num=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter is required; the second is optional. The default value of <code>num</code> is 10.\n",
    "\n",
    "If you only provide one argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_common(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>num</code> gets the default value. If you provide two arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_common(hist, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>num</code> gets the value of the argument instead. In other words, the optional argument overrides the default value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exercise 04***  \n",
    "\n",
    "Modify <code>subtract</code> that reads a word list (you have done this before!) and then prints all the words in the book that are not in the word list. How many of them are typos? How many of them are common words that should be in the word list, and how many of them are really obscure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random words\n",
    "\n",
    "\n",
    "### ***Exercise 05***  \n",
    "\n",
    "Write a function <code>random_word</code> that takes a histogram as defined in Dictionaries session and returns a random value from the histogram, chosen with probability in proportion to frequency. For example, for this histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(s):\n",
    "    d = {}\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 1\n",
    "        else:\n",
    "            d[c] += 1\n",
    "    return d\n",
    "\n",
    "t = ['a', 'a', 'b']\n",
    "hist = histogram(t)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your function should return `'a'` with probability 2/3 and `'b'` with probability 1/3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose a random word from the histogram, the simplest algorithm is to build a list with multiple copies of each word, according to the observed frequency, and then choose from the list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_word(h):\n",
    "    t = []\n",
    "    for word, freq in h.items():\n",
    "        t.extend([word] * freq)\n",
    "\n",
    "    return random.choice(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression <code>[word] * freq</code> creates a list with <code>freq</code> copies of the string <code>word</code>. The extend method is similar to append except that the argument is a sequence.\n",
    "\n",
    "This algorithm works, but it is not very efficient; each time you choose a random word, it rebuilds the list, which is as big as the original book. An obvious improvement is to build the list once and then make multiple selections, but the list is still big.\n",
    "\n",
    "An alternative is:\n",
    "\n",
    "1. Use keys to get a list of the words in the book.\n",
    "2. Build a list that contains the cumulative sum of the word frequencies. The last item in this list is the total number of words in the book, `n`.\n",
    "3. Choose a random number from `1` to `n`. Use a bisection search to find the index where the random number would be inserted in the cumulative sum.\n",
    "4. Use the index to find the corresponding word in the word list.\n",
    "\n",
    "\n",
    "\n",
    "### ***Exercise 06***\n",
    "\n",
    "Rewrite <code>random_word</code> that uses this algorithm to choose a random word from the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov analysis\n",
    "\n",
    "If you choose words from the book at random, you can get a sense of the vocabulary, but you probably won’t get a sentence:\n",
    "\n",
    "    this the small regard harriet which knightley's it most things\n",
    "\n",
    "A series of random words seldom makes sense because there is no relationship between successive words. For example, in a real sentence you would expect an article like “the” to be followed by an adjective or a noun, and probably not a verb or adverb.\n",
    "\n",
    "One way to measure these kinds of relationships is Markov analysis, which characterizes, for a given sequence of words, the probability of the words that might come next. For example, the song Eric, the Half a Bee begins:\n",
    "\n",
    "    Half a bee, philosophically,\n",
    "    Must, ipso facto, half not be.\n",
    "    But half the bee has got to be\n",
    "    Vis a vis, its entity. D’you see?\n",
    "\n",
    "    But can a bee be said to be\n",
    "    Or not to be an entire bee\n",
    "    When half the bee is not a bee\n",
    "    Due to some ancient injury?\n",
    "\n",
    "In this text, the phrase “half the” is always followed by the word “bee”, but the phrase “the bee” might be followed by either “has” or “is”.\n",
    "\n",
    "The result of Markov analysis is a mapping from each prefix (like “half the” and “the bee”) to all possible suffixes (like “has” and “is”).\n",
    "\n",
    "Given this mapping, you can generate a random text by starting with any prefix and choosing at random from the possible suffixes. Next, you can combine the end of the prefix and the new suffix to form the next prefix, and repeat.\n",
    "\n",
    "For example, if you start with the prefix “Half a”, then the next word has to be “bee”, because the prefix only appears once in the text. The next prefix is “a bee”, so the next suffix might be “philosophically”, “be” or “due”.\n",
    "\n",
    "In this example the length of the prefix is always two, but you can do Markov analysis with any prefix length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exercise 07*** (Optional)\n",
    "Markov analysis:\n",
    "\n",
    "1\\. Write a program to read a text from a file and perform Markov analysis. The result should be a dictionary that maps from prefixes to a collection of possible suffixes. The collection might be a list, tuple, or dictionary; it is up to you to make an appropriate choice. You can test your program with prefix length two, but you should write the program in a way that makes it easy to try other lengths.\n",
    "\n",
    "2\\. Add a function to the previous program to generate random text based on the Markov analysis. Here is an example from Emma with prefix length 2:\n",
    "\n",
    "        and the other day, of his cousins, their time passed till they reached the house. In the dining-room was large, for almost all its furniture, were examined and praised; and his wife, \"I cannot pretend to be expected?\" said he, \"do not make him desperate.\" The tumult of joy was \n",
    "\n",
    "For this example, I left the punctuation attached to the words. The result is almost syntactically correct, but not quite. Semantically, it almost makes sense, but not quite.\n",
    "\n",
    "What happens if you increase the prefix length? Does the random text make more sense?\n",
    "\n",
    "3\\. Once your program is working, you might want to try a mash-up: if you combine text from two or more books, the random text you generate will blend the vocabulary and phrases from the sources in interesting ways. \n",
    "\n",
    "Read *markov.py* to understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
